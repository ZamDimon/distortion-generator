"""
Package containing the Siamese Neural Network 
"""

import tensorflow as tf

from src.embeddings.hyperparameters import Hyperparameters
from src.embeddings.generator import TripletGenerator
from src.datasets import DatasetLoader

class TripletNetwork:
    """
    Triplet network is used for training Embedding model and uses three inputs: 
    - anchor - some image
    - positive - image from the same class as an anchor image 
    - negative - image from the different class than an anchor image
    """
    
    def __init__(self, 
                 embedding_model: tf.keras.models.Model, 
                 hyperparams: Hyperparameters):
        """
        Initializes an instance of a triplet network.
        
        Input:
        embedding_model - embedding model generated by the function above
        hyperparams - hyperparameters for the model
        
        Output:
        Siamese Neural Network and summary() output
        """
        
        self._hyperparams = hyperparams # Saving hyperparameters
        self._history = None # At some point we will save the history of the model
        
        input_anchor = tf.keras.layers.Input(shape=hyperparams.input_shape)
        input_positive = tf.keras.layers.Input(shape=hyperparams.input_shape)
        input_negative = tf.keras.layers.Input(shape=hyperparams.input_shape)

        embedding_anchor = embedding_model(input_anchor)
        embedding_positive = embedding_model(input_positive)
        embedding_negative = embedding_model(input_negative)

        output = tf.keras.layers.concatenate(
            [embedding_anchor, 
            embedding_positive, 
            embedding_negative], axis=1)
        
        triplet_network = tf.keras.models.Model([input_anchor, input_positive, input_negative], output)
        self._model = triplet_network
    
    def _triplet_distance_loss(self, _, y_predicted) -> tf.Tensor:
        """
        Calculates the triplet loss.
        """
        
        n = self._hyperparams.embedding_size
        anchor = y_predicted[:,:n]
        positive = y_predicted[:,n:(2*n)]
        negative = y_predicted[:,(2*n):]
        
        positive_distances = tf.reduce_mean(tf.square(anchor - positive), axis=1)
        negative_distances = tf.reduce_mean(tf.square(anchor - negative), axis=1)
        
        return tf.maximum(
            positive_distances - negative_distances + self._hyperparams.theta, 
            self._hyperparams.epsilon)
    
    def train(self, dataset: DatasetLoader) -> None:
        """
        Trains the model using the provided dataset loader.
        
        Arguments:
            - dataset (DatasetLoader): The dataset loader.
        """
        
        # We use legacy Adam optimizer since... well... M1 Macs don't support the new one
        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=self._hyperparams.learning_rate)
        self._model.compile(loss=self._triplet_distance_loss, optimizer=optimizer)
        
        (X_train, y_train), (X_test, y_test) = dataset.get()
        generator_train = TripletGenerator(
            X_train, 
            y_train, 
            self._hyperparams, 
            embedding_model=self._model
        )
        generator_validate = TripletGenerator(
            X_test, 
            y_test, 
            self._hyperparams, 
            embedding_model=self._model
        )

        self._history = self._model.fit(
            generator_train,
            epochs=self._hyperparams.epochs,
            verbose=1,
            validation_data=generator_validate,
            validation_steps=len(y_test)//self._hyperparams.batch_size
        )
    
    def get_history(self) -> tf.keras.callbacks.History:
        """
        Returns the history of the model and raises an error if the model hasn't yet been trained.
        """
        
        if self._history is None:
            raise Exception("The model hasn't been trained yet")
        
        return self._history
    
    def raw(self) -> tf.keras.models.Model:
        """
        Returns the model.
        """
        
        return self._model
    
    def summary(self) -> None:
        """
        Prints the model summary.
        """
        
        self._model.summary()